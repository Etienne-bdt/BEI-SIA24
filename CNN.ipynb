{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "xJxCG70XFQCF",
        "outputId": "90d8f42a-d007-4ad5-8583-e6680a751a8b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "ZtSBcJPunzNn",
        "outputId": "4cfdf93d-b55b-4ed9-9303-69cd2a1cd3cb"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bba80ba2d3f3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrXpfVV6F8CC"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70a6bU7-NGNn"
      },
      "source": [
        "data/\n",
        "\n",
        "│-- 2018/\n",
        "\n",
        "│   │-- image_1.npy\n",
        "\n",
        "│   │-- image_2.npy\n",
        "\n",
        "│   └-- ...\n",
        "\n",
        "│-- 2024/\n",
        "\n",
        "│   │-- image_1.npy\n",
        "\n",
        "│   │-- image_2.npy\n",
        "\n",
        "│   └-- ...\n",
        "\n",
        "│-- masks/  (zone de construction)\n",
        "\n",
        "│   │-- mask_1.npy\n",
        "\n",
        "│   │-- mask_2.npy\n",
        "\n",
        "│   └-- ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlM5C730Isk2"
      },
      "source": [
        "Get the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C66kVqmyI0pR"
      },
      "outputs": [],
      "source": [
        "data_dir_2018 = \"/path/to/2018/*.npy\" # 64 x 64 x 12bandes (dont masque)\n",
        "data_dir_2024 = \"/path/to/2024/*.npy\" # 64 x 64 x 11bandes\n",
        "\n",
        "# à vérifier si c'est bien sous forme de liste :\n",
        "#\n",
        "# import glob\n",
        "# data_dir_2018 = sorted(glob.glob(\"/path/to/2018/*.npy\"))\n",
        "# data_dir_2024 = sorted(glob.glob(\"/path/to/2024/*.npy\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF0T_SAqGytH"
      },
      "source": [
        "Prepare pytorch dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "zxv6b7ioF66D",
        "outputId": "6279131d-6149-49d9-ed1b-260c9975cac2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-518602642c3b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDatasetCadastre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir_2018\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir_2024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_2018\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir_2018\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_2024\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir_2024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdir_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "class DatasetCadastre(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir_2018, data_dir_2024, transform=None):\n",
        "        self.data_2018 = data_dir_2018\n",
        "        self.data_2024 = data_dir_2024\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Chargement des données\n",
        "        img_2018 = np.load(self.data_2018[index]).astype(np.float32) # (64, 64, 12)\n",
        "        img_2024 = np.load(self.data_2024[index]).astype(np.float32) # (64, 64, 11)\n",
        "\n",
        "        # Ajustement de l'ordre pytorch (channels, size)\n",
        "        img_2018 = np.transpose(img_2018, (2,0,1))\n",
        "        img_2024 = np.transpose(img_2024, (2,0,1))\n",
        "\n",
        "        # Transformation en tensor pytorch\n",
        "        img_2018 = torch.tensor(img_2018)\n",
        "        img_2024 = torch.tensor(img_2024)\n",
        "\n",
        "        # Si transformation appliquée\n",
        "        if self.transform:\n",
        "          img_2018 = self.transform(img_2018)\n",
        "          img_2024 = self.transform(img_2024)\n",
        "\n",
        "        return img_2018, img_2024\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_2018)\n",
        "\n",
        "# Dataset gobal --> à voir si on ne fait pas plutôt un dataset pour chaque donnée (2018 et 2024) ?\n",
        "cadastre_dataset = DatasetCadastre(data_dir_2018, data_dir_2024)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2kW5hYpX3L4"
      },
      "source": [
        "Prepare dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKsoNBHKX48M"
      },
      "outputs": [],
      "source": [
        "batch_size = 512\n",
        "num_threads = 4\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=cadastre_dataset, batch_size=batch_size, shuffle=True, num_workers=num_threads\n",
        ")\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    dataset=cadastre_dataset, batch_size=batch_size, shuffle=False, num_workers=num_threads\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh0Y2jNhZCgR"
      },
      "source": [
        "Normalize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fWB_NlVZHcZ"
      },
      "outputs": [],
      "source": [
        "# à voir car déjà normalisée ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVuBu24wZI4z"
      },
      "source": [
        "# Importe computed indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CdyzWOSZL9P"
      },
      "outputs": [],
      "source": [
        "# Permet de calculer les indices sur les bandes prédites (les indices vrais étant déjà compris dans une des bandes des images)\n",
        "\n",
        "import ...\n",
        "NDVI_commputed = ...\n",
        "...\n",
        "\n",
        "# def NDVI_computed(img_tensor):\n",
        "#     IR = img_tensor[...,:,:] # bande IR\n",
        "#     RED = img_tensor[...,:,:] # bande RED\n",
        "#     NDVI = (IR-RED)/(IR+RED)\n",
        "#     return NDVI\n",
        "\n",
        "# for img_2018, img_2024 in train_loader:\n",
        "#     NDVI_2018 = NDVI_computed(img_2018)\n",
        "#     NDVI_2024 = NDVI_computed(img_2024)\n",
        "#     break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhgjR_ROZ9I3"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTBtsncQZ8vV"
      },
      "outputs": [],
      "source": [
        "class Conv2DRegressionModel(nn.Module): # prédiction de l'image 2024\n",
        "    def __init__(self, int_channels: int = 12):\n",
        "        super(Conv2DRegressionModel, self).__init__()\n",
        "        self.nb_channel=int_channels\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(int_channels, 64, kernel_size=3, padding=1),\n",
        "            nn.LazyBatchNorm2d(),\n",
        "            # nn.BatchNorm2d(int_channels*2)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, kernel_size=2),\n",
        "            nn.Conv2d(64, 256, kernel_size=3, padding=1),\n",
        "            nn.LazyBatchNorm2d(),\n",
        "            # nn.BatchNorm2d(int_channels*4)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, kernel_size=2),\n",
        "            # nn.FullyConnected ?\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256*16*16, 64*64*(int_channels-1)),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(64*64, 64*64*(int_channels-1))\n",
        "        )\n",
        "\n",
        "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
        "        y = self.layers(X)\n",
        "        y= y.transforms.resize((self.nb_channel-1,64,64))\n",
        "        # y = y.view(-1, 64, 64) # sortie en image NDVI\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz851Jtlbh68"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ignite.metrics as im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4N79MD6bhV5"
      },
      "outputs": [],
      "source": [
        "n_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = Conv2DRegressionModel()\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# metric = im.SSIM(data_range=1.0)\n",
        "# metric.attach(im.default_evaluator, 'ssim')\n",
        "# preds = torch.rand([4, 3, 16, 16])\n",
        "# target = preds * 0.75\n",
        "# state = im.default_evaluator.run([[preds, target]])\n",
        "# print(state.metrics['ssim'])\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_set_len = len(train_loader)\n",
        "val_set_len = len(valid_loader)\n",
        "\n",
        "train_loss_comp, val_loss_comp = [], []\n",
        "train_loss_pred, val_loss_pred = [], []\n",
        "train_loss_comp_pred, val_loss_comp_pred = [], []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    accu_comp = 0.0\n",
        "    accu_pred = 0.0\n",
        "    accu_comp_pred = 0.0\n",
        "\n",
        "    for img_2018, img_2024 in train_loader:\n",
        "        # img_2018, img_2024 = img_2018.to(device), img_2024.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        img_2024_pred = model(img_2018) # image 2024 prédite à partir de 2018\n",
        "\n",
        "        # NDVI\n",
        "        NDVI_2018 = img_2018[:,...,:,:] # NDVI 2018 calculé présent à la bande ... (vrai)\n",
        "        NDVI_2024 = img_2024[:,...,:,:] # NDVI 2014 calculé présent à la bande ... (vrai)\n",
        "        NDVI_2024_comp = NDVI_computed(img_2024_pred) # NDVI 2024 caclulé à partir des bandes prédites\n",
        "        NDVI_2024_pred = img_2024_pred[:,...,:,:] # NDVI 2024 prédit par le réseau de neurones à la bande ...\n",
        "\n",
        "        # NDMI\n",
        "        NDMI_2018 = img_2018[:,...,:,:]\n",
        "        NDMI_2024 = img_2024[:,...,:,:]\n",
        "        NDMI_2024_comp = NDMI_computed(img_2024_pred)\n",
        "        NDMI_2024_pred = img_2024_pred[:,...,:,:]\n",
        "\n",
        "        # NDBI\n",
        "        NDBI_2018 = img_2018[:,...,:,:]\n",
        "        NDBI_2024 = img_2024[:,...,:,:]\n",
        "        NDBI_2024_comp = NDBI_computed(img_2024_pred)\n",
        "        NDBI_2024_pred = img_2024_pred[:,...,:,:]\n",
        "\n",
        "        # NDWI\n",
        "        NDWI_2018 = img_2018[:,...,:,:]\n",
        "        NDWI_2024 = img_2024[:,...,:,:]\n",
        "        NDWI_2024_comp = NDWI_computed(img_2024_pred)\n",
        "        NDWI_2024_pred = img_2024_pred[:,...,:,:]\n",
        "\n",
        "        # BSI\n",
        "        BSI_2018 = img_2018[:,...,:,:]\n",
        "        BSI_2024 = img_2024[:,...,:,:]\n",
        "        BSI_2024_comp = BSI_computed(img_2024_pred)\n",
        "        BSI_2024_pred = img_2024_pred[:,...,:,:]\n",
        "\n",
        "        # Regroupement des indices\n",
        "        Ind_2018 = [NDVI_2018, NDMI_2018, NDBI_2018, NDWI_2018, BSI_2018]\n",
        "        Ind_2024 = [NDVI_2024, NDMI_2024, NDBI_2024, NDWI_2024, BSI_2024]\n",
        "        Ind_2024_comp = [NDVI_2024_comp, NDMI_2024_comp, NDBI_2024_comp, NDWI_2024_comp, BSI_2024_comp]\n",
        "        Ind_2024_pred = [NDVI_2024_pred, NDMI_2024_pred, NDBI_2024_pred, NDWI_2024_pred, BSI_2024_pred]\n",
        "\n",
        "        weights = torch.tensor([0.4, 0.2, 0.2, 0.1, 0.1], device=device) # pondération à ajuster\n",
        "        loss_comp = sum(w * loss_fn(comp, true) for w, comp, true in zip(weights, Ind_2024_comp, Ind_2024)) # comparaison des indices calculés\n",
        "        loss_pred = sum(w * loss_fn(pred, true) for w, pred, true in zip(weights, Ind_2024_pred, Ind_2024)) # comparaison des indices prédits\n",
        "        loss_comp_pred = sum(w * loss_fn(comp, pred) for w, comp, pred in zip(weights, Ind_2024_comp, Ind_2024_pred)) # comparaison des indices calculés et prédits\n",
        "        total_loss = loss_comp + loss_pred + loss_comp_pred\n",
        "\n",
        "        accu_comp += loss_comp.item()\n",
        "        accu_pred += loss_pred.item()\n",
        "        accu_comp_pred += loss_comp_pred.item()\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss_comp.append(accu_comp / train_set_len)\n",
        "    train_loss_pred.append(accu_pred / train_set_len)\n",
        "    train_loss_comp_pred.append(accu_comp_pred / train_set_len)\n",
        "\n",
        "    # Validation - no gradient & eval mode\n",
        "    model.eval()\n",
        "    accu_comp = 0.0\n",
        "    accu_pred = 0.0\n",
        "    accu_comp_pred = 0.0\n",
        "    with torch.no_grad():\n",
        "        for img_2018, img_2024 in valid_loader:\n",
        "            # img_2018, img_2024 = img_2018.to(device), img_2024.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            img_2024_pred = model(img_2018) # image 2024 prédite à partir de 2018\n",
        "\n",
        "            # NDVI\n",
        "            NDVI_2018 = img_2018[:,...,:,:] # NDVI 2018 calculé présent à la bande ... (vrai)\n",
        "            NDVI_2024 = img_2024[:,...,:,:] # NDVI 2014 calculé présent à la bande ... (vrai)\n",
        "            NDVI_2024_comp = NDVI_computed(img_2024_pred) # NDVI 2024 caclulé à partir des bandes prédites\n",
        "            NDVI_2024_pred = img_2024_pred[:,...,:,:] # NDVI 2024 prédit par le réseau de neurones à la bande ...\n",
        "\n",
        "            # NDMI\n",
        "            NDMI_2018 = img_2018[:,...,:,:]\n",
        "            NDMI_2024 = img_2024[:,...,:,:]\n",
        "            NDMI_2024_comp = NDMI_computed(img_2024_pred)\n",
        "            NDMI_2024_pred = img_2024_pred[:,...,:,:]\n",
        "\n",
        "            # NDBI\n",
        "            NDBI_2018 = img_2018[:,...,:,:]\n",
        "            NDBI_2024 = img_2024[:,...,:,:]\n",
        "            NDBI_2024_comp = NDBI_computed(img_2024_pred)\n",
        "            NDBI_2024_pred = img_2024_pred[:,...,:,:]\n",
        "\n",
        "            # NDWI\n",
        "            NDWI_2018 = img_2018[:,...,:,:]\n",
        "            NDWI_2024 = img_2024[:,...,:,:]\n",
        "            NDWI_2024_comp = NDWI_computed(img_2024_pred)\n",
        "            NDWI_2024_pred = img_2024_pred[:,...,:,:]\n",
        "\n",
        "            # BSI\n",
        "            BSI_2018 = img_2018[:,...,:,:]\n",
        "            BSI_2024 = img_2024[:,...,:,:]\n",
        "            BSI_2024_comp = BSI_computed(img_2024_pred)\n",
        "            BSI_2024_pred = img_2024_pred[:,...,:,:]\n",
        "\n",
        "            # Regroupement des indices\n",
        "            Ind_2018 = [NDVI_2018, NDMI_2018, NDBI_2018, NDWI_2018, BSI_2018]\n",
        "            Ind_2024 = [NDVI_2024, NDMI_2024, NDBI_2024, NDWI_2024, BSI_2024]\n",
        "            Ind_2024_comp = [NDVI_2024_comp, NDMI_2024_comp, NDBI_2024_comp, NDWI_2024_comp, BSI_2024_comp]\n",
        "            Ind_2024_pred = [NDVI_2024_pred, NDMI_2024_pred, NDBI_2024_pred, NDWI_2024_pred, BSI_2024_pred]\n",
        "\n",
        "            weights = torch.tensor([0.4, 0.2, 0.2, 0.1, 0.1], device=device) # pondération à ajuster\n",
        "            loss_comp = sum(w * loss_fn(comp, true) for w, comp, true in zip(weights, Ind_2024_comp, Ind_2024)) # comparaison des indices calculés\n",
        "            loss_pred = sum(w * loss_fn(pred, true) for w, pred, true in zip(weights, Ind_2024_pred, Ind_2024)) # comparaison des indices prédits\n",
        "            loss_comp_pred = sum(w * loss_fn(comp, pred) for w, comp, pred in zip(weights, Ind_2024_comp, Ind_2024_pred)) # comparaison des indices calculés et prédits\n",
        "\n",
        "            accu_comp += loss_comp.item()\n",
        "            accu_pred += loss_pred.item()\n",
        "            accu_comp_pred += loss_comp_pred.item()\n",
        "        val_loss_comp.append(accu_comp / val_set_len)\n",
        "        val_loss_pred.append(accu_pred / val_set_len)\n",
        "        val_loss_comp_pred.append(accu_comp_pred / val_set_len)\n",
        "\n",
        "         # Save the best models\n",
        "        if val_loss_comp[-1] == min(val_loss_comp):\n",
        "            torch.save(model.state_dict(), \"save_model_comp.pt\")\n",
        "            print(\"Model 'comp' saved for epoch\", epoch)\n",
        "        if val_loss_pred[-1] == min(val_loss_pred):\n",
        "            torch.save(model.state_dict(), \"save_model_pred.pt\")\n",
        "            print(\"Model 'pred' saved for epoch\", epoch)\n",
        "        if val_loss_comp_pred[-1] == min(val_loss_comp_pred):\n",
        "            torch.save(model.state_dict(), \"save_model_comp_pred.pt\")\n",
        "            print(\"Model 'comp_pred' saved for epoch\", epoch)\n",
        "\n",
        "    print(\"Train loss 'comp'\", train_loss_comp[-1])\n",
        "    print(\"Val loss 'comp'\", val_loss_comp[-1])\n",
        "\n",
        "    print(\"Train loss 'pred'\", train_loss_pred[-1])\n",
        "    print(\"Val loss 'pred'\", val_loss_pred[-1])\n",
        "\n",
        "    print(\"Train loss 'comp_pred'\", train_loss_comp_pred[-1])\n",
        "    print(\"Val loss 'comp_pred'\", val_loss_comp_pred[-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0MWL3EKl3Kw"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_loss_comp, label=\"Train Loss 'comp'\")\n",
        "plt.plot(val_loss_comp, label=\"Validation Loss 'comp'\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_loss_pred, label=\"Train Loss 'pred'\")\n",
        "plt.plot(val_loss_pred, label=\"Validation Loss 'pred'\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_loss_comp_pred, label=\"Train Loss 'comp_pred'\")\n",
        "plt.plot(val_loss_comp_pred, label=\"Validation Loss 'comp_pred'\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
