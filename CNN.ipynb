{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/Etienne-bdt/BEI-SIA25\n",
        "!unzip /content/BEI-SIA25/data.zip /content/BEI-SIA25/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "xJxCG70XFQCF",
        "outputId": "90d8f42a-d007-4ad5-8583-e6680a751a8b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "from utils.dataloader import CadastreSen2Dataset\n",
        "from utils.index_calculation import BSI, NDBI, NDMI, NDVI, NDWI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "ZtSBcJPunzNn",
        "outputId": "4cfdf93d-b55b-4ed9-9303-69cd2a1cd3cb"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrXpfVV6F8CC"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlM5C730Isk2"
      },
      "source": [
        "Get the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF0T_SAqGytH"
      },
      "source": [
        "Prepare pytorch dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "zxv6b7ioF66D",
        "outputId": "6279131d-6149-49d9-ed1b-260c9975cac2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No numpy patches found in ./data/31035\\patches\n",
            "No numpy patches found in ./data/57591\\patches\n"
          ]
        }
      ],
      "source": [
        "dataset = CadastreSen2Dataset(image_path=\"./data/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2kW5hYpX3L4"
      },
      "source": [
        "Prepare dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hKsoNBHKX48M"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "num_threads = 0\n",
        "\n",
        "#Split into train and validation\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_threads)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_threads)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhgjR_ROZ9I3"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MTBtsncQZ8vV"
      },
      "outputs": [],
      "source": [
        "class Conv2DRegressionModel(nn.Module): # prÃ©diction de l'image 2024\n",
        "    def __init__(self, int_channels: int = 11):\n",
        "        super(Conv2DRegressionModel, self).__init__()\n",
        "        self.nb_channel=int_channels\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(int_channels, 64, kernel_size=3, padding=1),\n",
        "            nn.LazyBatchNorm2d(),\n",
        "            # nn.BatchNorm2d(int_channels*2)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2,2)),\n",
        "            nn.Conv2d(64, 256, kernel_size=3, padding=1),\n",
        "            nn.LazyBatchNorm2d(),\n",
        "            # nn.BatchNorm2d(int_channels*4)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2,2)),\n",
        "            # nn.FullyConnected ?\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256*16*16, 64*64*(int_channels-1)),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(64*64, 64*64*(int_channels-1))\n",
        "        )\n",
        "\n",
        "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
        "        y = self.layers(X)\n",
        "        y= y.view(-1, self.nb_channel-1, 64, 64)\n",
        "        # y = y.view(-1, 64, 64) # sortie en image NDVI\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz851Jtlbh68"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ignite.metrics as im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "e4N79MD6bhV5"
      },
      "outputs": [
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 10.00 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.00 GiB is allocated by PyTorch, and 681.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m Conv2DRegressionModel()\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# metric = im.SSIM(data_range=1.0)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# metric.attach(im.default_evaluator, 'ssim')\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# preds = torch.rand([4, 3, 16, 16])\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# target = preds * 0.75\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# state = im.default_evaluator.run([[preds, target]])\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# print(state.metrics['ssim'])\u001b[39;00m\n\u001b[0;32m     15\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1155\u001b[0m             device,\n\u001b[0;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m             non_blocking,\n\u001b[0;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1159\u001b[0m         )\n\u001b[1;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.00 GiB is allocated by PyTorch, and 681.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "n_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = Conv2DRegressionModel()\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# metric = im.SSIM(data_range=1.0)\n",
        "# metric.attach(im.default_evaluator, 'ssim')\n",
        "# preds = torch.rand([4, 3, 16, 16])\n",
        "# target = preds * 0.75\n",
        "# state = im.default_evaluator.run([[preds, target]])\n",
        "# print(state.metrics['ssim'])\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_set_len = len(train_loader)\n",
        "val_set_len = len(val_loader)\n",
        "\n",
        "train_loss_comp, val_loss_comp = [], []\n",
        "train_loss_pred, val_loss_pred = [], []\n",
        "train_loss_comp_pred, val_loss_comp_pred = [], []\n",
        "train_loss_tot, val_loss_tot = [], []\n",
        "best_loss=1000000\n",
        "for epoch in tqdm(range(n_epochs)):\n",
        "    model.train()\n",
        "    accu_comp = 0.0\n",
        "    accu_pred = 0.0\n",
        "    accu_comp_pred = 0.0\n",
        "    accu_total = 0.0\n",
        "\n",
        "    for x, y, mask in train_loader:\n",
        "        x,y,mask = x.to(device), y.to(device), mask.to(device)\n",
        "        x,y,mask = x.float(), y.float(), mask.float()\n",
        "        optimizer.zero_grad()\n",
        "        # img_2018, img_2024 = img_2018.to(device), img_2024.to(device)\n",
        "        # Forward pass\n",
        "        in_x = torch.cat((x, mask), dim=1)\n",
        "        y_pred = model(in_x) # image 2024 prÃ©dite Ã  partir de 2018\n",
        "\n",
        "        Ind_comp = [NDVI(y_pred), NDWI(y_pred), NDBI(y_pred), NDMI(y_pred), BSI(y_pred)] # indices calculÃ©s\n",
        "        Ind_real = y[:,5:,:,:]\n",
        "        Ind_pred = y_pred[:,5:,:,:]\n",
        "        weights = torch.tensor([0.4, 0.2, 0.2, 0.1, 0.1], device=device) # pondÃ©ration Ã  ajuster\n",
        "        loss_comp = sum(w * loss_fn(comp, true) for w, comp, true in zip(weights, Ind_comp, Ind_real)) # comparaison des indices calculÃ©s\n",
        "        loss_pred = sum(w * loss_fn(pred, true) for w, pred, true in zip(weights, Ind_pred, Ind_real)) # comparaison des indices prÃ©dits\n",
        "        loss_comp_pred = sum(w * loss_fn(comp, pred) for w, comp, pred in zip(weights, Ind_comp, Ind_pred)) # comparaison des indices calculÃ©s et prÃ©dits\n",
        "        total_loss = loss_comp + loss_pred + loss_comp_pred\n",
        "\n",
        "        accu_comp += loss_comp.item()\n",
        "        accu_pred += loss_pred.item()\n",
        "        accu_comp_pred += loss_comp_pred.item()\n",
        "        accu_total += total_loss.item()\n",
        "        # Backward pass\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss_comp.append(accu_comp / train_set_len)\n",
        "    train_loss_pred.append(accu_pred / train_set_len)\n",
        "    train_loss_comp_pred.append(accu_comp_pred / train_set_len)\n",
        "    train_loss_tot.append(accu_total / train_set_len)\n",
        "    # Validation - no gradient & eval mode\n",
        "    model.eval()\n",
        "    accu_comp = 0.0\n",
        "    accu_pred = 0.0\n",
        "    accu_comp_pred = 0.0\n",
        "    accu_total = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y, mask in val_loader:\n",
        "            x,y,mask = x.to(device), y.to(device), mask.to(device)\n",
        "            x,y,mask = x.float(), y.float(), mask.float()\n",
        "            in_x = torch.cat((x, mask), dim=1)\n",
        "            y_pred = model(in_x)\n",
        "\n",
        "            Ind_comp = [NDVI(y_pred), NDWI(y_pred), NDBI(y_pred), NDMI(y_pred), BSI(y_pred)]\n",
        "            Ind_real = y[:,5:,:,:]\n",
        "            Ind_pred = y_pred[:,5:,:,:]\n",
        "            weights = torch.tensor([0.4, 0.2, 0.2, 0.1, 0.1], device=device)\n",
        "            loss_comp = sum(w * loss_fn(comp, true) for w, comp, true in zip(weights, Ind_comp, Ind_real))\n",
        "            loss_pred = sum(w * loss_fn(pred, true) for w, pred, true in zip(weights, Ind_pred, Ind_real))\n",
        "            loss_comp_pred = sum(w * loss_fn(comp, pred) for w, comp, pred in zip(weights, Ind_comp, Ind_pred))\n",
        "            total_loss = loss_comp + loss_pred + loss_comp_pred\n",
        "\n",
        "            accu_comp += loss_comp.item()\n",
        "            accu_pred += loss_pred.item()\n",
        "            accu_comp_pred += loss_comp_pred.item()\n",
        "            accu_total += total_loss.item()\n",
        "\n",
        "    val_loss_comp.append(accu_comp / val_set_len)\n",
        "    val_loss_pred.append(accu_pred / val_set_len)\n",
        "    val_loss_comp_pred.append(accu_comp_pred / val_set_len)\n",
        "    val_loss_tot.append(accu_total / val_set_len)\n",
        "\n",
        "    if accu_total < best_loss:\n",
        "        best_loss = accu_total\n",
        "        torch.save(model.state_dict(), \"best_model.pt\")\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs} - Train loss: {train_loss_tot[-1]:.4f} - Val loss: {val_loss_tot[-1]:.4f}\")\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        torch.save(model.state_dict(), f\"model_{epoch}.pt\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0MWL3EKl3Kw"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_loss_comp, label=\"Train Loss 'comp'\")\n",
        "plt.plot(val_loss_comp, label=\"Validation Loss 'comp'\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_loss_pred, label=\"Train Loss 'pred'\")\n",
        "plt.plot(val_loss_pred, label=\"Validation Loss 'pred'\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_loss_comp_pred, label=\"Train Loss 'comp_pred'\")\n",
        "plt.plot(val_loss_comp_pred, label=\"Validation Loss 'comp_pred'\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
