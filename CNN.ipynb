{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJxCG70XFQCF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "ZtSBcJPunzNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the data"
      ],
      "metadata": {
        "id": "RrXpfVV6F8CC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "data/\n",
        "\n",
        "│-- 2018/\n",
        "\n",
        "│   │-- image_1.npy\n",
        "\n",
        "│   │-- image_2.npy\n",
        "\n",
        "│   └-- ...\n",
        "\n",
        "│-- 2024/\n",
        "\n",
        "│   │-- image_1.npy\n",
        "\n",
        "│   │-- image_2.npy\n",
        "\n",
        "│   └-- ...\n",
        "\n",
        "│-- masks/  (zone de construction)\n",
        "\n",
        "│   │-- mask_1.npy\n",
        "\n",
        "│   │-- mask_2.npy\n",
        "\n",
        "│   └-- ..."
      ],
      "metadata": {
        "id": "70a6bU7-NGNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importe data from google drive"
      ],
      "metadata": {
        "id": "Nuc000icHLKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# à voir si c'est bien fait en forme de liste"
      ],
      "metadata": {
        "id": "qYZAQz4yHJgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the data"
      ],
      "metadata": {
        "id": "YlM5C730Isk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data : 64 x 64 x 10bandes\n",
        "\n",
        "data_dir_2018 = \"/...\"\n",
        "data_dir_2024 = \"/...\"\n",
        "mask_dir = \"/...\"\n"
      ],
      "metadata": {
        "id": "C66kVqmyI0pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare pytorch dataset"
      ],
      "metadata": {
        "id": "JF0T_SAqGytH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetCadastre(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir_2018, data_dir_2024, mask_dir, transform=None):\n",
        "        self.data_2018 = data_dir_2018\n",
        "        self.data_2024 = data_dir_2024\n",
        "        self.mask_path = mask_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Chargement des données\n",
        "        img_2018 = np.load(self.data_2018[index]).astype(np.float32) # (64, 64, 10)\n",
        "        img_2024 = np.load(self.data_2024[index]).astype(np.float32)\n",
        "        mask = np.load(self.mask_path[index]).astype(np.float32)\n",
        "\n",
        "        # Ajustement de l'ordre pytorch (channels, size)\n",
        "        img_2018 = np.transpose(img_2018, (2,0,1))\n",
        "        img_2024 = np.transpose(img_2024, (2,0,1))\n",
        "        mask = np.expand_dims(mask, axis=0)\n",
        "\n",
        "        # Transformation en tensor pytorch\n",
        "        img_2018 = torch.tensor(img_2018)\n",
        "        img_2024 = torch.tensor(img_2024)\n",
        "        mask = torch.tensor(mask)\n",
        "\n",
        "        # Si transformation appliquée\n",
        "        if self.transform:\n",
        "          img_2018 = self.transform(img_2018)\n",
        "          img_2024 = self.transform(img_2024)\n",
        "\n",
        "        return img_2018, img_2024, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_2018)\n",
        "\n",
        "# Dataset gobal --> à voir si on fait pas plutôt un dataset pour chaque donnée (2018, 204 et mask)\n",
        "cadastre_dataset = DatasetCadastre(data_dir_2018, data_dir_2024, mask_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "zxv6b7ioF66D",
        "outputId": "6279131d-6149-49d9-ed1b-260c9975cac2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-518602642c3b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDatasetCadastre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir_2018\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir_2024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_2018\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir_2018\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_2024\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir_2024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdir_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare dataloader"
      ],
      "metadata": {
        "id": "V2kW5hYpX3L4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512\n",
        "num_threads = 4\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=cadastre_dataset, batch_size=batch_size, shuffle=True, num_workers=num_threads\n",
        ")\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    dataset=cadastre_dataset, batch_size=batch_size, shuffle=False, num_workers=num_threads\n",
        ")"
      ],
      "metadata": {
        "id": "hKsoNBHKX48M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize data"
      ],
      "metadata": {
        "id": "dh0Y2jNhZCgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# à voir"
      ],
      "metadata": {
        "id": "8fWB_NlVZHcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute NDVI"
      ],
      "metadata": {
        "id": "KVuBu24wZI4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NDVI_computed(img_tensor):\n",
        "    IR = img_tensor[...,:,:] # bande IR\n",
        "    RED = img_tensor[...,:,:] # bande RED\n",
        "    NDVI = (IR-RED)/(IR+RED)\n",
        "    return NDVI\n",
        "\n",
        "# for img_2018, img_2024, mask in train_loader:\n",
        "#     NDVI_2018 = NDVI_computed(img_2018)\n",
        "#     NDVI_2024 = NDVI_computed(img_2024)\n",
        "#     break"
      ],
      "metadata": {
        "id": "1CdyzWOSZL9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model definition"
      ],
      "metadata": {
        "id": "MhgjR_ROZ9I3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2DRegressionModel(nn.Module): # prédiction d'indices (NDVI, ...)\n",
        "    def __init__(self, int_channels: int = 10):\n",
        "        super(Conv2DRegressionModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(int_channels, 32, kernel_size=3, padding=1),\n",
        "            nn.LazyBatchNorm2d(),\n",
        "            # nn.BatchNorm2d(int_channels*2)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, kernel_size=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.LazyBatchNorm2d(),\n",
        "            # nn.BatchNorm2d(int_channels*4)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, kernel_size=2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128*8*8, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 64*64)\n",
        "        )\n",
        "\n",
        "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
        "        y = self.layers(X)\n",
        "        y = y.view(-1, 64, 64) # sortie en image NDVI\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "MTBtsncQZ8vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "gz851Jtlbh68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = Conv2DRegressionModel()\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_set_len = len(train_loader)\n",
        "val_set_len = len(valid_loader)\n",
        "\n",
        "train_loss_comp, val_loss_comp = [], []\n",
        "train_loss_pred, val_loss_pred = [], []\n",
        "train_loss_comp_pred, val_loss_comp_pred = [], []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    accu_comp = 0.0\n",
        "    accu_pred = 0.0\n",
        "    accu_comp_pred = 0.0\n",
        "\n",
        "    for img_2018, img_2024, mask in train_loader:\n",
        "        # img_2018, img_2024, mask = img_2018.to(device), img_2024.to(device), mask.to(device)\n",
        "        # Forward pass\n",
        "        img_2024_pred = model(img_2018) # image 2024 prédite à partir de 2018\n",
        "\n",
        "        NDVI_2018 = NDVI_computed(img_2018) # NDVI 2018 calculé (vrai)\n",
        "        NDVI_2024 = NDVI_computed(img_2024) # NDVI 2024 calculé (vrai)\n",
        "\n",
        "        NDVI_2024_comp = NDVI_computed(img_2024_pred) # NDVI 2024 caclulé à partir des bandes prédites\n",
        "\n",
        "        NDVI_2024_pred = ... # NDVI 2024 prédit par le réseau de neurones\n",
        "\n",
        "        loss_comp = loss_fn(NDVI_2024_comp, NDVI_2024) # comparaison des NDVI avec calcul\n",
        "        loss_pred = loss_fn(NDVI_2024_pred, NDVI_2024) # comparaison des NDVI avec prédiction\n",
        "        loss_comp_pred = loss_fn(NDVI_2024_comp, NDVI_2024_pred) # comparaison des NDVI calculé et prédit\n",
        "\n",
        "        accu_comp += loss_comp.item()\n",
        "        accu_pred += loss_pred.item()\n",
        "        accu_comp_pred += loss_comp_pred.item()\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss_comp.backward()\n",
        "        loss_pred.backward()\n",
        "        loss_comp_pred.backward()\n",
        "        optimizer.step()\n",
        "    train_loss_comp.append(accu_comp / train_set_len)\n",
        "    train_loss_pred.append(accu_pred / train_set_len)\n",
        "    train_loss_comp_pred.append(accu_comp_pred / train_set_len)\n",
        "\n",
        "    # Validation - no gradient & eval mode\n",
        "    model.eval()\n",
        "    accu_comp = 0.0\n",
        "    accu_pred = 0.0\n",
        "    accu_comp_pred = 0.0\n",
        "    with torch.no_grad():\n",
        "        for img_2018, img_2024, mask in valid_loader:\n",
        "            # img_2018, img_2024, mask = img_2018.to(device), img_2024.to(device), mask.to(device)\n",
        "            # Forward pass\n",
        "            img_2024_pred = model(img_2018) # image 2024 prédite à partir de 2018\n",
        "            NDVI_2018 = NDVI_computed(img_2018) # NDVI 2018 calculé (vrai)\n",
        "            NDVI_2024 = NDVI_computed(img_2024) # NDVI 2024 calculé (vrai)\n",
        "            NDVI_2024_comp = NDVI_computed(img_2024_pred) # NDVI 2024 caclulé à partir des bandes prédites\n",
        "            NDVI_2024_pred = ... # NDVI 2024 prédit par le réseau de neurones\n",
        "\n",
        "            loss_comp = loss_fn(NDVI_2024_comp, NDVI_2024) # comparaison des NDVI avec calcul\n",
        "            loss_pred = loss_fn(NDVI_2024_pred, NDVI_2024) # comparaison des NDVI avec prédiction\n",
        "            loss_comp_pred = loss_fn(NDVI_2024_comp, NDVI_2024_pred) # comparaison des NDVI calculé et prédit\n",
        "\n",
        "            accu_comp += loss_comp.item()\n",
        "            accu_pred += loss_pred.item()\n",
        "            accu_comp_pred += loss_comp_pred.item()\n",
        "    valid_loss_comp.append(accu_comp / valid_set_len)\n",
        "    valid_loss_pred.append(accu_pred / valid_set_len)\n",
        "    valid_loss_comp_pred.append(accu_comp_pred / valid_set_len)\n",
        "\n",
        "         # Save the best models\n",
        "        if val_loss_comp[-1] == min(val_loss_comp):\n",
        "            torch.save(model.state_dict(), \"save_model_comp.pt\")\n",
        "            print(\"Model 'comp' saved for epoch\", epoch)\n",
        "        if val_loss_pred[-1] == min(val_loss_pred):\n",
        "            torch.save(model.state_dict(), \"save_model_pred.pt\")\n",
        "            print(\"Model 'pred' saved for epoch\", epoch)\n",
        "        if val_loss_comp_pred[-1] == min(val_loss_comp_pred):\n",
        "            torch.save(model.state_dict(), \"save_model_comp_pred.pt\")\n",
        "            print(\"Model 'comp_pred' saved for epoch\", epoch)\n",
        "\n",
        "    print(\"Train loss 'comp'\", train_loss_comp[-1])\n",
        "    print(\"Val loss 'comp'\", val_loss_comp[-1])\n",
        "\n",
        "    print(\"Train loss 'pred'\", train_loss_pred[-1])\n",
        "    print(\"Val loss 'pred'\", val_loss_pred[-1])\n",
        "\n",
        "    print(\"Train loss 'comp_pred'\", train_loss_comp_pred[-1])\n",
        "    print(\"Val loss 'comp_pred'\", val_loss_comp_pred[-1])\n",
        ""
      ],
      "metadata": {
        "id": "e4N79MD6bhV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss_comp, label=\"Train Loss 'comp'\")\n",
        "plt.plot(val_loss_comp, label=\"Validation Loss 'comp'\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_loss_pred, label=\"Train Loss 'pred'\")\n",
        "plt.plot(val_loss_pred, label=\"Validation Loss 'pred'\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "lt.plot(train_loss_comp_pred, label=\"Train Loss 'comp_pred'\")\n",
        "plt.plot(val_loss_comp_pred, label=\"Validation Loss 'comp_pred'\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X0MWL3EKl3Kw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}